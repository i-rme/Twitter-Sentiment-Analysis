{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis RME.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brNqUQ4hav1W",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis of Tweets\n",
        "Based on \"2.5 Machine Learning Text Classification\", adapted and improved by Raúl Martínez.\n",
        "\n",
        "In this problem we wil be training several models to classify tweets based on sentiment.\n",
        "\n",
        "They will be three categories, Positive, Negative and Neutral.\n",
        "\n",
        "We will be using a open dataset loaded below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeAh9QXoRbLM",
        "colab_type": "text"
      },
      "source": [
        "# 1.- Loading the dataset\n",
        "\n",
        "We open the dataset from a CSV file and replace null values with NA string.\n",
        "\n",
        "We print our data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSLWBLMIdda3",
        "colab_type": "code",
        "outputId": "09b7b09d-9ab2-4a9d-b729-de952cd0693c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv('https://raw.githubusercontent.com/marrrcin/ml-twitter-sentiment-analysis/develop/data/train.csv', na_values=['NA']);\n",
        "\n",
        "tweets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>635769805279248384</td>\n",
              "      <td>negative</td>\n",
              "      <td>Not Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>635930169241374720</td>\n",
              "      <td>neutral</td>\n",
              "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>635950258682523648</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Mar if you have an iOS device, you should down...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>636030803433009153</td>\n",
              "      <td>negative</td>\n",
              "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>636100906224848896</td>\n",
              "      <td>positive</td>\n",
              "      <td>Not sure how to start your publication on iOS?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5965</th>\n",
              "      <td>639016598477651968</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5966</th>\n",
              "      <td>640276909633486849</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5967</th>\n",
              "      <td>640296841725235200</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>641017384908779520</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Not Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5969</th>\n",
              "      <td>641395811474128896</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Not Available</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5970 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Id  ...                                              Tweet\n",
              "0     635769805279248384  ...                                      Not Available\n",
              "1     635930169241374720  ...  IOS 9 App Transport Security. Mm need to check...\n",
              "2     635950258682523648  ...  Mar if you have an iOS device, you should down...\n",
              "3     636030803433009153  ...  @jimmie_vanagon my phone does not run on lates...\n",
              "4     636100906224848896  ...  Not sure how to start your publication on iOS?...\n",
              "...                  ...  ...                                                ...\n",
              "5965  639016598477651968  ...  @YouAreMyArsenal Wouldn't surprise me if we en...\n",
              "5966  640276909633486849  ...  Rib injury for Zlatan against Russia is a big ...\n",
              "5967  640296841725235200  ...  Noooooo! I was hoping to see Zlatan being Zlat...\n",
              "5968  641017384908779520  ...                                      Not Available\n",
              "5969  641395811474128896  ...                                      Not Available\n",
              "\n",
              "[5970 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OccRkXJVg7c6",
        "colab_type": "text"
      },
      "source": [
        "# 2.- Cleaning the data\n",
        "\n",
        "Remove all the rows that contain a \"Not Available\" tweet because they are not real tweets, they are issues on our data. [1]\n",
        "\n",
        "This raises our score by 4 percentage points.\n",
        "\n",
        "We need to reset the index numbers to avoid errors below. [2]\n",
        "\n",
        "We print again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPPLVRxrepsp",
        "colab_type": "code",
        "outputId": "0b838ffe-eef9-4bae-d534-8611fd8d18cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "tweets = tweets.drop(tweets[tweets.Tweet == \"Not Available\"].index)\n",
        "\n",
        "tweets = tweets.reset_index(drop=True)\n",
        "\n",
        "tweets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>635930169241374720</td>\n",
              "      <td>neutral</td>\n",
              "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>635950258682523648</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Mar if you have an iOS device, you should down...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>636030803433009153</td>\n",
              "      <td>negative</td>\n",
              "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>636100906224848896</td>\n",
              "      <td>positive</td>\n",
              "      <td>Not sure how to start your publication on iOS?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>636176272947744772</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Two Dollar Tuesday is here with Forklift 2, Qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5417</th>\n",
              "      <td>638445576212754433</td>\n",
              "      <td>positive</td>\n",
              "      <td>Ok ed let's do this, Zlatan, greizmann and Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5418</th>\n",
              "      <td>638531837313306624</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Goal level: Zlatan  90k by Friday? = Posting e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5419</th>\n",
              "      <td>639016598477651968</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5420</th>\n",
              "      <td>640276909633486849</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5421</th>\n",
              "      <td>640296841725235200</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5422 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Id  ...                                              Tweet\n",
              "0     635930169241374720  ...  IOS 9 App Transport Security. Mm need to check...\n",
              "1     635950258682523648  ...  Mar if you have an iOS device, you should down...\n",
              "2     636030803433009153  ...  @jimmie_vanagon my phone does not run on lates...\n",
              "3     636100906224848896  ...  Not sure how to start your publication on iOS?...\n",
              "4     636176272947744772  ...  Two Dollar Tuesday is here with Forklift 2, Qu...\n",
              "...                  ...  ...                                                ...\n",
              "5417  638445576212754433  ...  Ok ed let's do this, Zlatan, greizmann and Lap...\n",
              "5418  638531837313306624  ...  Goal level: Zlatan  90k by Friday? = Posting e...\n",
              "5419  639016598477651968  ...  @YouAreMyArsenal Wouldn't surprise me if we en...\n",
              "5420  640276909633486849  ...  Rib injury for Zlatan against Russia is a big ...\n",
              "5421  640296841725235200  ...  Noooooo! I was hoping to see Zlatan being Zlat...\n",
              "\n",
              "[5422 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCUbGR6Chm3u",
        "colab_type": "text"
      },
      "source": [
        "Delete the Id collumn from our dataset as this does not contain useful information. [3] \n",
        "\n",
        "We print again to see our result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LZjwgD5fSEx",
        "colab_type": "code",
        "outputId": "6fa541b7-dad0-4816-d5aa-31d9df73c244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "del tweets['Id']\n",
        "\n",
        "tweets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Mar if you have an iOS device, you should down...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>Not sure how to start your publication on iOS?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Two Dollar Tuesday is here with Forklift 2, Qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5417</th>\n",
              "      <td>positive</td>\n",
              "      <td>Ok ed let's do this, Zlatan, greizmann and Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5418</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Goal level: Zlatan  90k by Friday? = Posting e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5419</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5420</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5421</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5422 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Category                                              Tweet\n",
              "0      neutral  IOS 9 App Transport Security. Mm need to check...\n",
              "1      neutral  Mar if you have an iOS device, you should down...\n",
              "2     negative  @jimmie_vanagon my phone does not run on lates...\n",
              "3     positive  Not sure how to start your publication on iOS?...\n",
              "4      neutral  Two Dollar Tuesday is here with Forklift 2, Qu...\n",
              "...        ...                                                ...\n",
              "5417  positive  Ok ed let's do this, Zlatan, greizmann and Lap...\n",
              "5418   neutral  Goal level: Zlatan  90k by Friday? = Posting e...\n",
              "5419   neutral  @YouAreMyArsenal Wouldn't surprise me if we en...\n",
              "5420   neutral  Rib injury for Zlatan against Russia is a big ...\n",
              "5421   neutral  Noooooo! I was hoping to see Zlatan being Zlat...\n",
              "\n",
              "[5422 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmMtt8_Ch2HZ",
        "colab_type": "text"
      },
      "source": [
        "Remove urls from Tweets as they do not have information about the sentiment of the tweet. [4]\n",
        "\n",
        "We print our result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMe41Hf6iAjd",
        "colab_type": "code",
        "outputId": "f571db5c-1be3-4911-b7bb-1dad29561193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Example of tweet before removing urls.\n",
        "print(tweets.loc[2]['Tweet'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REOm3uPMgORv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets['Tweet'] = tweets['Tweet'].str.replace('http\\S+|www.\\S+', '', case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1B4Y6oKgWV2",
        "colab_type": "code",
        "outputId": "9acabf43-2353-4755-f443-0d34491b7237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Example of tweet after removing urls.\n",
        "print(tweets.loc[2]['Tweet'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@jimmie_vanagon my phone does not run on latest IOS which may account for problem the other day .. time it was replaced\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "690grAbJiYML",
        "colab_type": "text"
      },
      "source": [
        "Remove twitter handles using Regex, as they do not affect sentiment of a tweet. [5] [6] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwqoyHSYipyC",
        "colab_type": "code",
        "outputId": "21925ae6-a7c0-45ee-cc35-07d23b2db378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Example of tweet before removing twitter handles.\n",
        "print(tweets.loc[3]['Tweet'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not sure how to start your publication on iOS? We'll be live helping with ask me anything sessions today and Friday \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wFwq1uPiJlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets['Tweet'] = tweets['Tweet'].str.replace('\\B@\\w+', '', case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTT3uUpWh3pw",
        "colab_type": "code",
        "outputId": "941d762b-0246-4543-c46d-a8ef898d79a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Example of tweet after removing twitter handles.\n",
        "print(tweets.loc[3]['Tweet'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not sure how to start your publication on iOS? We'll be live helping with ask me anything sessions today and Friday \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmfBQDxpi3Rq",
        "colab_type": "text"
      },
      "source": [
        "Replace double spaces with single spaces and saving the clean dataset in a new variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc1Rpu48jx71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets['Tweet'] = tweets['Tweet'].str.replace('  ', ' ', case=False)\n",
        "\n",
        "tweets_clean = tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCMVVkMojATZ",
        "colab_type": "text"
      },
      "source": [
        "We can print only the Tweet collumn by using this syntax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuKX1nFC8DQ1",
        "colab_type": "code",
        "outputId": "5d89c701-035f-418a-ab70-61db6864ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "tweets_clean['Tweet']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       IOS 9 App Transport Security. Mm need to check...\n",
              "1       Mar if you have an iOS device, you should down...\n",
              "2        my phone does not run on latest IOS which may...\n",
              "3       Not sure how to start your publication on iOS?...\n",
              "4       Two Dollar Tuesday is here with Forklift 2, Qu...\n",
              "                              ...                        \n",
              "5417    Ok ed let's do this, Zlatan, greizmann and Lap...\n",
              "5418    Goal level: Zlatan 90k by Friday? = Posting ev...\n",
              "5419     Wouldn't surprise me if we enquired.He can't ...\n",
              "5420    Rib injury for Zlatan against Russia is a big ...\n",
              "5421    Noooooo! I was hoping to see Zlatan being Zlat...\n",
              "Name: Tweet, Length: 5422, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W64DoVu6jTiv",
        "colab_type": "text"
      },
      "source": [
        "# 3.- First approach to classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TADA2OecmWUa",
        "colab_type": "text"
      },
      "source": [
        "We split our collumns into X and Y and perform a train test split with 20% of the records going to testing and 80% to training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r941FaclBir",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = tweets['Tweet']\n",
        "Y = tweets['Category']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=1005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHytWBsxtHUn",
        "colab_type": "text"
      },
      "source": [
        "We reindex our data to get index numbers that start from 0 and go secuentially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f1NWioEtH5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "\n",
        "Y_train = Y_train.reset_index(drop=True)\n",
        "Y_test = Y_test.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij__KAGLmnge",
        "colab_type": "text"
      },
      "source": [
        "We extract features from text files and print its shape.\n",
        "\n",
        "4337 samples with 9973 diffent words in them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKSOgnWS70kQ",
        "colab_type": "code",
        "outputId": "dd2a6d7c-0409-493c-88b1-a38dd72370ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4066, 9581)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqhPZOPmnHev",
        "colab_type": "text"
      },
      "source": [
        "For example, the first tweet contains the following words this number of times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E0eY9bO8PMP",
        "colab_type": "code",
        "outputId": "62c6fff4-6d83-4e81-a8d7-bd51899b127d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(X_train_counts[0,:])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8831)\t1\n",
            "  (0, 6862)\t1\n",
            "  (0, 7257)\t1\n",
            "  (0, 8104)\t1\n",
            "  (0, 2742)\t1\n",
            "  (0, 7560)\t1\n",
            "  (0, 7230)\t1\n",
            "  (0, 1783)\t1\n",
            "  (0, 9385)\t1\n",
            "  (0, 8090)\t1\n",
            "  (0, 2586)\t1\n",
            "  (0, 1006)\t1\n",
            "  (0, 8517)\t1\n",
            "  (0, 1816)\t1\n",
            "  (0, 9471)\t1\n",
            "  (0, 3855)\t1\n",
            "  (0, 622)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yez7MNignaAA",
        "colab_type": "text"
      },
      "source": [
        "Now we start our Term frequency - Inverse document frequency algorithm that works as explained on lectures, by assigning variable weights on terms depending on its rarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29cJktao8S5l",
        "colab_type": "code",
        "outputId": "71da3672-2cfe-4ffb-ec6a-6535da499c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4066, 9581)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_bTczGcnxxZ",
        "colab_type": "text"
      },
      "source": [
        "This TF-IDF algorithm generates this weights for each of the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MthW3xW8UlH",
        "colab_type": "code",
        "outputId": "5ae44011-a820-412a-ef83-e99071dc256e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(X_train_tfidf[0,:])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 9471)\t0.23083673217385792\n",
            "  (0, 9385)\t0.10001067621412355\n",
            "  (0, 8831)\t0.16629181626209993\n",
            "  (0, 8517)\t0.05374210727430672\n",
            "  (0, 8104)\t0.1789048679921987\n",
            "  (0, 8090)\t0.3071022480426049\n",
            "  (0, 7560)\t0.2679510132050171\n",
            "  (0, 7257)\t0.3071022480426049\n",
            "  (0, 7230)\t0.24974672570212947\n",
            "  (0, 6862)\t0.1938459763607244\n",
            "  (0, 3855)\t0.16951746301835324\n",
            "  (0, 2742)\t0.28240056909450734\n",
            "  (0, 2586)\t0.2926526921531146\n",
            "  (0, 1816)\t0.2926526921531146\n",
            "  (0, 1783)\t0.3071022480426049\n",
            "  (0, 1006)\t0.213054189116479\n",
            "  (0, 622)\t0.3071022480426049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFAx-QKcoC1I",
        "colab_type": "text"
      },
      "source": [
        "# 4.- The classifier\n",
        "\n",
        "Machine Learning\n",
        "\n",
        "Training the classifier on training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2F4AOR88XQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = MultinomialNB().fit(X_train_tfidf, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRsuJa2Ao5zy",
        "colab_type": "text"
      },
      "source": [
        "Building a pipeline:\n",
        "\n",
        "We can write less code and do all of the above, by building a pipeline as follows:\n",
        "\n",
        "The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "\n",
        "We will be using the 'text_clf' going forward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfqzz7nF8zjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "text_clf = text_clf.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea4cQNC2ptlJ",
        "colab_type": "text"
      },
      "source": [
        "Performance of the classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZdKLwja8519",
        "colab_type": "code",
        "outputId": "cc5402d2-f758-4547-84fc-68c12c7e0452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted = text_clf.predict(X_test)\n",
        "np.mean(predicted == Y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5663716814159292"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY8dJ2rpp-CP",
        "colab_type": "text"
      },
      "source": [
        "We got a 56,6% score, that is an improvement from the random baseline that would be 33% (as they are 3 classes to choose between).\n",
        "\n",
        "We can do better than this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DEfBFX49OFd",
        "colab_type": "code",
        "outputId": "8ab5acd5-88d4-4e32-e244-6e7f40a74b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "print(\"Real:\")\n",
        "print(Y_test[801])\n",
        "print(Y_test[802])\n",
        "print(Y_test[803])\n",
        "\n",
        "print(\"\\nPredictions:\")\n",
        "print(predicted[801])\n",
        "print(predicted[802])\n",
        "print(predicted[803])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real:\n",
            "positive\n",
            "neutral\n",
            "negative\n",
            "\n",
            "Predictions:\n",
            "positive\n",
            "neutral\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKBwOm2buMac",
        "colab_type": "text"
      },
      "source": [
        "We can confirm that our output series is the same lenght as our predicted series. A non equal shape will be an indicator of bad code and would lead to incorrect answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj56tadjuNFm",
        "colab_type": "code",
        "outputId": "f8eaf9cb-86b9-4df7-ffb7-be65d659a208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(\"Y_test shape:\")\n",
        "print(Y_test.shape)\n",
        "\n",
        "print(\"\\nPredicted Shape:\")\n",
        "print(predicted.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_test shape:\n",
            "(1356,)\n",
            "\n",
            "Predicted Shape:\n",
            "(1356,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1zIAo-Fu721",
        "colab_type": "text"
      },
      "source": [
        "# 5.- Using SVM\n",
        "\n",
        "Training Support Vector Machines - SVM and calculating its performance.\n",
        "\n",
        "SGD is a optimization method used in machine learning models that defines a loss function, and the optimization method maximizes or minimizes it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4agPiROzHLMF",
        "colab_type": "code",
        "outputId": "2ef052e6-c8f0-4999-80ef-c6234f79095f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=1004))])\n",
        "\n",
        "text_clf_svm = text_clf_svm.fit(X_train, Y_train)\n",
        "predicted_svm = text_clf_svm.predict(X_test)\n",
        "np.mean(predicted_svm == Y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5759587020648967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zz02Py_veLq",
        "colab_type": "text"
      },
      "source": [
        "We get a 58% by using SGD Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5cToe6cv0GF",
        "colab_type": "text"
      },
      "source": [
        "We can do grid search for SVM to explore the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNCIdUWCHhxF",
        "colab_type": "code",
        "outputId": "ae5ccbe7-e0ab-4f21-a6c8-51bb5eb9d63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
        "\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "print(gs_clf_svm.best_score_)\n",
        "print(gs_clf_svm.best_params_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5459911460895229\n",
            "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxJoW28lHqCt",
        "colab_type": "code",
        "outputId": "d014da35-3597-404c-afe4-7ef93848533b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gs_clf_svm.best_score_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5459911460895229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnU7c-OlwO3S",
        "colab_type": "text"
      },
      "source": [
        "We get as ouput the best parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_sIuXj7wR__",
        "colab_type": "text"
      },
      "source": [
        "Now we will use the Natural Language Toolkit to remove stop words, these are words without real meaning.\n",
        "\n",
        "We will choose the stop word list from English language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO5g_WATHr5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), \n",
        "                     ('clf', MultinomialNB())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKcI8HSTwosM",
        "colab_type": "text"
      },
      "source": [
        "Stemming is the process of producing variants of a base word. [7] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVU7iFQXHu9J",
        "colab_type": "code",
        "outputId": "7016c48e-8012-4c75-d40e-faad37546274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "\n",
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
        "    \n",
        "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
        "\n",
        "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
        "                             ('mnb', MultinomialNB(fit_prior=False))])\n",
        "\n",
        "text_mnb_stemmed = text_mnb_stemmed.fit(X_train, Y_train)\n",
        "\n",
        "predicted_mnb_stemmed = text_mnb_stemmed.predict(X_test)\n",
        "\n",
        "np.mean(predicted_mnb_stemmed == Y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5870206489675516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr85CGntxTzx",
        "colab_type": "text"
      },
      "source": [
        "This gets us a 59% of accuracy agains our testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyi1GTbt-2Qt",
        "colab_type": "text"
      },
      "source": [
        "# 6.- Fixing Imbalanced Dataset\n",
        "\n",
        "In the full dataset we have detected an issue, the distribution of the classess is the following:\n",
        "\n",
        "- Positive: 2889/5970 = 48,4%\n",
        "- Neutral: 2127/5970 = 35,6%\n",
        "- Negative: 959/5970 = 16,1%\n",
        "\n",
        "Our dataset has more samples of positive and neutral tweets than negative ones, we must take this into account. [13]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0FFOhd7EzwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, Y_resampled = ros.fit_resample(X_train.values.reshape(-1, 1), Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBv8kek6-zOq",
        "colab_type": "text"
      },
      "source": [
        "We import our oversampler and we initiate it giving providing the X and Y input variables. [8]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meALV5L5G2yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_OS = pd.Series(X_resampled[:, 0])\n",
        "Y_train_OS = pd.Series(Y_resampled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuI93lru_AWy",
        "colab_type": "text"
      },
      "source": [
        "We have converted the output into pandas series. [9]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6YyGNqC_LGU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Here we can see the before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7OzN5ZCFrKM",
        "colab_type": "code",
        "outputId": "e2bb6d24-4ee0-477a-f513-ae62ebe7f34a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "print(X_train);\n",
        "print(Y_train);"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       IOS 9 App Transport Security. Mm need to check...\n",
            "1       Mar if you have an iOS device, you should down...\n",
            "2        my phone does not run on latest IOS which may...\n",
            "3       Not sure how to start your publication on iOS?...\n",
            "4       Two Dollar Tuesday is here with Forklift 2, Qu...\n",
            "                              ...                        \n",
            "4332    Is Tiger Woods form finally returning or is it...\n",
            "4333     Hi jamie I heard Tiger Woods was at -13 Under...\n",
            "4334    Belgian Grand Prix, 100m Final, Super Sunday, ...\n",
            "4335    Tiger Woods 2 strokes behind leader Jason Gore...\n",
            "4336    \"Tiger Woods doesn't move the needle. He is th...\n",
            "Name: Tweet, Length: 4337, dtype: object\n",
            "0        neutral\n",
            "1        neutral\n",
            "2       negative\n",
            "3       positive\n",
            "4        neutral\n",
            "          ...   \n",
            "4332     neutral\n",
            "4333     neutral\n",
            "4334     neutral\n",
            "4335    positive\n",
            "4336    positive\n",
            "Name: Category, Length: 4337, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iopij7xE_QVe",
        "colab_type": "text"
      },
      "source": [
        "And its imbalanced shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0sdP0ehAwso",
        "colab_type": "code",
        "outputId": "949f9f9b-199f-4423-e53b-112ef4cdbaee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(tweets[tweets.Category == \"positive\"].shape)\n",
        "\n",
        "print(tweets[tweets.Category == \"neutral\"].shape)\n",
        "\n",
        "print(tweets[tweets.Category == \"negative\"].shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2599, 2)\n",
            "(1953, 2)\n",
            "(869, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3xRZn85_SVV",
        "colab_type": "text"
      },
      "source": [
        "Now, after the oversampling we observe the same number of rows in each category, as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UfSYXBnOAY1",
        "colab_type": "code",
        "outputId": "6107b9cf-9e09-4e67-b119-e72017f86583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(Y_train_OS[Y_train_OS == \"positive\"].shape)\n",
        "\n",
        "print(Y_train_OS[Y_train_OS == \"neutral\"].shape)\n",
        "\n",
        "print(Y_train_OS[Y_train_OS == \"negative\"].shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2147,)\n",
            "(2147,)\n",
            "(2147,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am0MLM6y_bG0",
        "colab_type": "text"
      },
      "source": [
        "We can print one category to show if they are all of the expected category:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEfHYngQOTwA",
        "colab_type": "code",
        "outputId": "6654ef4c-f098-46ef-d280-fcefb5435a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "Y_train_OS[Y_train_OS == \"neutral\"]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       neutral\n",
              "1       neutral\n",
              "4       neutral\n",
              "5       neutral\n",
              "6       neutral\n",
              "         ...   \n",
              "6436    neutral\n",
              "6437    neutral\n",
              "6438    neutral\n",
              "6439    neutral\n",
              "6440    neutral\n",
              "Length: 2147, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C1WX-3t_je5",
        "colab_type": "text"
      },
      "source": [
        "Also we can check the actual oversampled neutral tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl7cClZlOYv_",
        "colab_type": "code",
        "outputId": "9d40bc8b-635f-4071-a0fd-888a228a5e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "X_train_OS[Y_train_OS == \"neutral\"]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       IOS 9 App Transport Security. Mm need to check...\n",
              "1       Mar if you have an iOS device, you should down...\n",
              "4       Two Dollar Tuesday is here with Forklift 2, Qu...\n",
              "5       If you're not already signed up to test my iOS...\n",
              "6       YouTube Gaming Officially Launches On Web, And...\n",
              "                              ...                        \n",
              "6436    For sure just Missed my exit because was singi...\n",
              "6437    That moment when you live in NYC but you're at...\n",
              "6438    Anybody asking what law #KimDavis broke needs ...\n",
              "6439    Harry talking to the 9 year old boy/auctioning...\n",
              "6440    ICYMI: Heres what you must know about Texas' d...\n",
              "Length: 2147, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhf1fDen_oIC",
        "colab_type": "text"
      },
      "source": [
        "Now we initiate the same CountVectorizer, TFIDF and process explained in the chapters before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLm2FfqPDZp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "test_count_vect = CountVectorizer()\n",
        "test_X_train_counts = test_count_vect.fit_transform(X_train_OS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNztqqcO9VFN",
        "colab_type": "code",
        "outputId": "f1275ac3-9e12-4e2e-b07b-e5f47959f940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "test_tfidf_transformer = TfidfTransformer()\n",
        "test_X_train_tfidf = test_tfidf_transformer.fit_transform(test_X_train_counts)\n",
        "\n",
        "\n",
        "# Machine Learning\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "test_clf = MultinomialNB().fit(test_X_train_tfidf, Y_train_OS)\n",
        "\n",
        "\n",
        "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
        "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "# We will be using the 'text_clf' going forward.\n",
        "from sklearn.pipeline import Pipeline\n",
        "#test_text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "#test_text_clf = test_text_clf.fit(X_train_OS, Y_train_OS)\n",
        "\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=1004))])\n",
        "text_clf_svm = text_clf_svm.fit(X_train_OS, Y_train_OS)\n",
        "\n",
        "# Performance of NB Classifier\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "test_predicted = text_clf_svm.predict(X_test)\n",
        "print(np.mean(test_predicted == Y_test))\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7160766961651918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6aJko_1AHwO",
        "colab_type": "text"
      },
      "source": [
        "Wow, this is our highest score yet by using SVM and by fixing the imbalanced dataset problem.\n",
        "\n",
        "We can compare this accuracy agains a random predicted sample by shuffling the testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ARcojULPzyD",
        "colab_type": "code",
        "outputId": "02caae6e-8f0a-4eb0-efc6-5f7b78754454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_predicted = text_clf_svm.predict(X_test)\n",
        "print(np.mean(test_predicted == Y_test.sample(frac=1)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3635693215339233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_peX5UjAaf5",
        "colab_type": "text"
      },
      "source": [
        "We can observe that a fully trained model gets 70,4% of accuracy choosing between 3 classes and below the expected output from a random model that just tries without clue, that is called the baseline.\n",
        "\n",
        "Baseline: 37,1%\n",
        "\n",
        "Our model: 70,4%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQK329B7aV6C",
        "colab_type": "text"
      },
      "source": [
        "# 7.- Bagging\n",
        "\n",
        "Using techniques like Boosting or Baggin can help to increase the robustness and decrease the variance of the model. By combining multiple models we can decrease variance thus producing a more reliable classification than a single model could provide. [10] [11]\n",
        "\n",
        "Bagging consists on aggregating a group of models into a common output, that could consist on averaging the answers of each model to produce consensus. This is a simple but very powerful ensemble method. \n",
        "\n",
        "Boosting consists in grouping models outputs by utilizing weighted averages to make weak learners into stronger learners. \n",
        "\n",
        "These techniques decrease the variance of your single estimate as they combine several estimates from different models.\n",
        "\n",
        "In this practice we will try bagging by aggregating three models built with subsets of the train dataset.\n",
        "\n",
        "The method to build these subsets will be sampling with replacement, as this is the recommended method by the available literature. [12]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMo8j8IVrk9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "0f4ea9df-ecb9-41ca-d356-ec47f6449131"
      },
      "source": [
        "print(tweets_clean)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Category                                              Tweet\n",
            "0      neutral  IOS 9 App Transport Security. Mm need to check...\n",
            "1      neutral  Mar if you have an iOS device, you should down...\n",
            "2     negative   my phone does not run on latest IOS which may...\n",
            "3     positive  Not sure how to start your publication on iOS?...\n",
            "4      neutral  Two Dollar Tuesday is here with Forklift 2, Qu...\n",
            "...        ...                                                ...\n",
            "5417  positive  Ok ed let's do this, Zlatan, greizmann and Lap...\n",
            "5418   neutral  Goal level: Zlatan 90k by Friday? = Posting ev...\n",
            "5419   neutral   Wouldn't surprise me if we enquired.He can't ...\n",
            "5420   neutral  Rib injury for Zlatan against Russia is a big ...\n",
            "5421   neutral  Noooooo! I was hoping to see Zlatan being Zlat...\n",
            "\n",
            "[5422 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNhFwGcMrmuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_clean_train = tweets_clean[0:4337]\n",
        "tweets_clean_test = tweets_clean[4337:5422]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3heyFJHhsRon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "c0b0dd13-3156-4c36-a543-d1e05260ae14"
      },
      "source": [
        "print(tweets_clean_train)\n",
        "\n",
        "print(tweets_clean_test)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Category                                              Tweet\n",
            "0      neutral  IOS 9 App Transport Security. Mm need to check...\n",
            "1      neutral  Mar if you have an iOS device, you should down...\n",
            "2     negative   my phone does not run on latest IOS which may...\n",
            "3     positive  Not sure how to start your publication on iOS?...\n",
            "4      neutral  Two Dollar Tuesday is here with Forklift 2, Qu...\n",
            "...        ...                                                ...\n",
            "4332   neutral  Is Tiger Woods form finally returning or is it...\n",
            "4333   neutral   Hi jamie I heard Tiger Woods was at -13 Under...\n",
            "4334   neutral  Belgian Grand Prix, 100m Final, Super Sunday, ...\n",
            "4335  positive  Tiger Woods 2 strokes behind leader Jason Gore...\n",
            "4336  positive  \"Tiger Woods doesn't move the needle. He is th...\n",
            "\n",
            "[4337 rows x 2 columns]\n",
            "      Category                                              Tweet\n",
            "4337   neutral  Vintage 2008 Tiger Woods on master sunday on t...\n",
            "4338  positive  Bolt wins an epic. Imagine if Tiger Woods wins...\n",
            "4339   neutral  2015 Wyndham Championship: Tee times, pairings...\n",
            "4340  positive  A Sunday with Tiger Woods in contention for a ...\n",
            "4341  positive  Hello Tiger family. Do the #Tigertwirlchalleng...\n",
            "...        ...                                                ...\n",
            "5417  positive  Ok ed let's do this, Zlatan, greizmann and Lap...\n",
            "5418   neutral  Goal level: Zlatan 90k by Friday? = Posting ev...\n",
            "5419   neutral   Wouldn't surprise me if we enquired.He can't ...\n",
            "5420   neutral  Rib injury for Zlatan against Russia is a big ...\n",
            "5421   neutral  Noooooo! I was hoping to see Zlatan being Zlat...\n",
            "\n",
            "[1085 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv9cTcOXhQdF",
        "colab_type": "code",
        "outputId": "828910c8-cd9f-42c9-a1a4-5187a65bedea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# We are extracting our data with replacement\n",
        "# We shuffle our dataset in each extraction by using the sample method of pandas\n",
        "# We also reset the index\n",
        "\n",
        "# Notice that in each bag we are selecting 40% of the rows, this is not a problem\n",
        "# as we are using replacement so 3 x 40% = 120% is not a problem.\n",
        "\n",
        "bag1_tweets = tweets_clean_train.sample(frac=0.40).reset_index(drop=True)\n",
        "print(bag1_tweets)\n",
        "#print(bag1_tweets_train[bag1_tweets_train.Category == \"positive\"].shape)\n",
        "#print(bag1_tweets_train[bag1_tweets_train.Category == \"negative\"].shape)\n",
        "\n",
        "bag2_tweets = tweets_clean_train.sample(frac=0.40).reset_index(drop=True)\n",
        "#print(bag2_tweets)\n",
        "#print(bag2_tweets_train[bag2_tweets_train.Category == \"positive\"].shape)\n",
        "#print(bag2_tweets_train[bag2_tweets_train.Category == \"negative\"].shape)\n",
        "\n",
        "bag3_tweets = tweets_clean_train.sample(frac=0.40).reset_index(drop=True)\n",
        "#print(bag3_tweets)\n",
        "#print(bag3_tweets_train[bag3_tweets_train.Category == \"positive\"].shape)\n",
        "#print(bag3_tweets_train[bag3_tweets_train.Category == \"negative\"].shape)\n",
        "\n",
        "# We got 1735 rows in each bag"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Category                                              Tweet\n",
            "0     negative  One of my Magic Mike XXL co-workers and the co...\n",
            "1     positive  For all the fans outthere: Kurt Cobain's 1st b...\n",
            "2     negative  Oracle so transparently bought sun just to sue...\n",
            "3      neutral  Nokia n97 microcosm - bear down upon the whole...\n",
            "4      neutral   I don't either. Complete mystery. Also, I may...\n",
            "...        ...                                                ...\n",
            "1730  positive  Nintendo may go back to carts  also make so I ...\n",
            "1731   neutral  I'm freezing my butt off at the drive ins to w...\n",
            "1732  positive  Taylor Swift is Coming Toronto,ON October 2nd ...\n",
            "1733   neutral   the jobs were created cause the economy antic...\n",
            "1734   neutral  ORACLE GUIDANCE AUG 13 2015 : if you know what...\n",
            "\n",
            "[1735 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCTmcNIDjqzM",
        "colab_type": "code",
        "outputId": "34edaf0b-9af3-4213-98f9-aef70676a1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bag1_count_vect = CountVectorizer()\n",
        "bag1_X_train_counts = bag1_count_vect.fit_transform(bag1_tweets['Tweet'])\n",
        "bag2_count_vect = CountVectorizer()\n",
        "bag2_X_train_counts = bag2_count_vect.fit_transform(bag2_tweets['Tweet'])\n",
        "bag3_count_vect = CountVectorizer()\n",
        "bag3_X_train_counts = bag3_count_vect.fit_transform(bag3_tweets['Tweet'])\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "bag1_tfidf_transformer = TfidfTransformer()\n",
        "bag1_X_train_tfidf = bag1_tfidf_transformer.fit_transform(bag1_X_train_counts)\n",
        "bag2_tfidf_transformer = TfidfTransformer()\n",
        "bag2_X_train_tfidf = bag2_tfidf_transformer.fit_transform(bag2_X_train_counts)\n",
        "bag3_tfidf_transformer = TfidfTransformer()\n",
        "bag3_X_train_tfidf = bag3_tfidf_transformer.fit_transform(bag3_X_train_counts)\n",
        "\n",
        "# Machine Learning\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
        "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "# We will be using the 'text_clf' going forward.\n",
        "from sklearn.pipeline import Pipeline\n",
        "bag1_text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', RandomForestClassifier())])\n",
        "bag1_text_clf = bag1_text_clf.fit(bag1_tweets['Tweet'], bag1_tweets['Category'])\n",
        "bag2_text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "bag2_text_clf = bag2_text_clf.fit(bag2_tweets['Tweet'], bag2_tweets['Category'])\n",
        "#bag3_text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', DecisionTreeClassifier())])\n",
        "#bag3_text_clf = bag3_text_clf.fit(bag3_tweets['Tweet'], bag3_tweets['Category'])\n",
        "\n",
        "bag3_text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=1004))])\n",
        "bag3_text_clf = bag3_text_clf.fit(bag3_tweets['Tweet'], bag3_tweets['Category'])\n",
        "\n",
        "# Performance of NB Classifier\n",
        "import numpy as np\n",
        "\n",
        "bag1_predicted = bag1_text_clf.predict(tweets_clean_test['Tweet'])\n",
        "print(np.mean(bag1_predicted == tweets_clean_test['Category']))\n",
        "\n",
        "bag2_predicted = bag2_text_clf.predict(tweets_clean_test['Tweet'])\n",
        "print(np.mean(bag2_predicted == tweets_clean_test['Category']))\n",
        "\n",
        "bag3_predicted = bag3_text_clf.predict(tweets_clean_test['Tweet'])\n",
        "print(np.mean(bag3_predicted == tweets_clean_test['Category']))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.447926267281106\n",
            "0.4488479262672811\n",
            "0.4663594470046083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JNKKPr6O7qn",
        "colab_type": "text"
      },
      "source": [
        "This custom function was created in an attempt to aggregate the output from our 3 bags, it does so by querying each model then adding the outputs and finally making a decision based on a numeric range that can be adjusted.\n",
        "\n",
        "Finally it outputs an array just as the normal prediction functions remaining compatible with non-bagging code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQsEh6Us2m7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bagged_predict(input_tweet):\n",
        "    prediction_1 = bag1_text_clf.predict(input_tweet)\n",
        "    prediction_2 = bag2_text_clf.predict(input_tweet)\n",
        "    prediction_3 = bag3_text_clf.predict(input_tweet)\n",
        "    output = []\n",
        "\n",
        "    for i in range(len(prediction_1)):\n",
        "      #print(i, prediction_1[i])\n",
        "      \n",
        "      recuento = 0  # Possible values: -3, -2, -1, 0, 1, 2, 3\n",
        "      result = \"neutral\"\n",
        "\n",
        "      if prediction_1[i] == \"positive\":\n",
        "        recuento = recuento + 1\n",
        "      if prediction_1[i] == \"negative\":\n",
        "        recuento = recuento - 1\n",
        "      if prediction_2[i] == \"positive\":\n",
        "        recuento = recuento + 1\n",
        "      if prediction_2[i] == \"negative\":\n",
        "        recuento = recuento - 1\n",
        "      if prediction_3[i] == \"positive\":\n",
        "        recuento = recuento + 1\n",
        "      if prediction_3[i] == \"negative\":\n",
        "        recuento = recuento - 1\n",
        "      if recuento <= -2:\n",
        "        result = \"negative\"\n",
        "      if recuento >= 3:\n",
        "        result = \"positive\"\n",
        "      output.append(result)\n",
        "\n",
        "    #print(output)\n",
        "    return(output)\n",
        "\n",
        "#print( bagged_predict([\"dont\",\"a\"]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsGl7Bko6X6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6c0da80-76bb-44a2-ec24-32decb7b80ab"
      },
      "source": [
        "bagged_predicted = bagged_predict(tweets_clean_test['Tweet'])\n",
        "print(np.mean(bagged_predicted == tweets_clean_test['Category']))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47557603686635946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUKIjZU2PUJ8",
        "colab_type": "text"
      },
      "source": [
        "We obtain a result above the baseline but its not the one that we expected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdpmk6oROKm4",
        "colab_type": "text"
      },
      "source": [
        "# 8.- Bibliography\n",
        "\n",
        "[1] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
        "\n",
        "[2] https://www.geeksforgeeks.org/python-pandas-dataframe-reset_index/\n",
        "\n",
        "[3] https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe\n",
        "\n",
        "[4] https://stackoverflow.com/questions/45395676/remove-a-url-row-by-row-from-a-large-set-of-text-in-python-panda-dataframe\n",
        "\n",
        "[5] https://stackoverflow.com/questions/20282452/regex-to-match-word-beginning-with\n",
        "\n",
        "[6] https://stackoverflow.com/questions/13851535/delete-rows-from-a-pandas-dataframe-based-on-a-conditional-expression-involving\n",
        "\n",
        "[7] https://www.geeksforgeeks.org/python-stemming-words-with-nltk/\n",
        "\n",
        "[8] https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
        "\n",
        "[9] https://stackoverflow.com/questions/33246771/convert-pandas-data-frame-to-series\n",
        "\n",
        "[10] https://becominghuman.ai/ensemble-learning-bagging-and-boosting-d20f38be9b1e\n",
        "\n",
        "[11] https://machinelearningmastery.com/how-to-create-a-random-split-cross-validation-and-bagging-ensemble-for-deep-learning-in-keras/\n",
        "\n",
        "[12] https://www.youtube.com/watch?v=2Mg8QD0F1dQ\n",
        "\n",
        "[13] https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a\n",
        "\n",
        "[ ] https://www.geeksforgeeks.org/ml-bagging-classifier/\n",
        "\n",
        "[ ] https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyx_KP_oCDI6",
        "colab_type": "text"
      },
      "source": [
        "# 9.- Conclusion\n",
        "\n",
        "Features included in the system:\n",
        "*   Invalid tweet removing (Dropping Not Available tweets)\n",
        "*   Tweet bloat removing (Urls, twitter handles, double spaces and IDs)\n",
        "*   Initial model using CV, TF-IDF and Multinomial Naive Bayes implementation\n",
        "*   Improved model using SVM - SDG\n",
        "*   Stopwords remover\n",
        "*   Fixing imbalanced dataset using RandomOverSampler\n",
        "*   Bagging approach using custom made bagging function\n",
        "\n",
        "In this practice we have learned that by using TF-IDF we can approach text classification machine learning problems just as any number based classification problem.\n",
        "\n",
        "Also we've learned that its important to clean our dataset to obtain significant accuracy gains, that simple models like MultinomialNB work relatively well but they can be improved by adding some advancements as SVM, SDG, removing stopwords and doing some tweaks as Oversampling classess with less rows to achieve even better results agains our baseline.\n",
        "\n",
        "We have been introduced to bagging as a method to aggregate outputs from diffent models trained using subsets of our train data.\n",
        "\n",
        "My skills related to machine learning have clearly increased as I knew only some theory when we started this course and now im able to perform some approximations to real problems such as this one.\n",
        "\n",
        "I've assigned about 6 to 10 hours to this practice, part of this time has been researching on the internet to understand how everything worked and then I've tried my best to implement them and also contribute with my own skills. This calculation does not include the lectures that have been important to understand our task.\n",
        "\n",
        "In conclusion, we have obtained a maximum accuracy of 70% by using SVM model with balanced datasets. That is 34 percentage points above our baseline of 36% so I consider it a success.\n",
        "\n",
        "The problems with this tasks in my opinion were related to the dataset, it contained few tweets for our models to understand the difference between classes, as text classification is much harder problem because the input comes from humans writing.\n"
      ]
    }
  ]
}